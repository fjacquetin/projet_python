{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## La version de python utilisée est 3.12.7\n",
    "\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import lxml as lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import io as io\n",
    "import math\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import json\n",
    "from pandasgui import show\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from folium.plugins import HeatMap\n",
    "import nbconvert\n",
    "\n",
    "from script import process_data\n",
    "from script import geolocaliser\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ce premier importe la base \"Demande de valeurs foncières\" (DVF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_17180\\904652215.py:18: DtypeWarning: Columns (8,10,12,14,17,18,20,22,26,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"full.csv\",encoding=\"utf-8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                0                    1  \\\n",
      "id_mutation                                2023-1               2023-1   \n",
      "date_mutation                          2023-01-05           2023-01-05   \n",
      "numero_disposition                              1                    1   \n",
      "nature_mutation                             Vente                Vente   \n",
      "valeur_fonciere                         1070000.0            1070000.0   \n",
      "adresse_numero                              184.0                159.0   \n",
      "adresse_suffixe                               NaN                  NaN   \n",
      "adresse_nom_voie                   ALL DES HETRES       ALL DES HETRES   \n",
      "adresse_code_voie                            0124                 0124   \n",
      "code_postal                                1630.0               1630.0   \n",
      "code_commune                                 1354                 1354   \n",
      "nom_commune                   Saint-Genis-Pouilly  Saint-Genis-Pouilly   \n",
      "code_departement                                1                    1   \n",
      "ancien_code_commune                           NaN                  NaN   \n",
      "ancien_nom_commune                            NaN                  NaN   \n",
      "id_parcelle                        01354000BD0334       01354000BD0336   \n",
      "ancien_id_parcelle                            NaN                  NaN   \n",
      "numero_volume                                 NaN                  NaN   \n",
      "lot1_numero                                    29                   22   \n",
      "lot1_surface_carrez                           NaN                  NaN   \n",
      "lot2_numero                                   NaN                  NaN   \n",
      "lot2_surface_carrez                           NaN                  NaN   \n",
      "lot3_numero                                   NaN                  NaN   \n",
      "lot3_surface_carrez                           NaN                  NaN   \n",
      "lot4_numero                                   NaN                  NaN   \n",
      "lot4_surface_carrez                           NaN                  NaN   \n",
      "lot5_numero                                   NaN                  NaN   \n",
      "lot5_surface_carrez                           NaN                  NaN   \n",
      "nombre_lots                                     1                    1   \n",
      "code_type_local                               3.0                  2.0   \n",
      "type_local                             Dépendance          Appartement   \n",
      "surface_reelle_bati                           NaN                233.0   \n",
      "nombre_pieces_principales                     0.0                  8.0   \n",
      "code_nature_culture                           NaN                  NaN   \n",
      "nature_culture                                NaN                  NaN   \n",
      "code_nature_culture_speciale                  NaN                  NaN   \n",
      "nature_culture_speciale                       NaN                  NaN   \n",
      "surface_terrain                               NaN                  NaN   \n",
      "longitude                                6.019949             6.020204   \n",
      "latitude                                46.247458            46.247228   \n",
      "\n",
      "                                                2                  3  \\\n",
      "id_mutation                                2023-1             2023-2   \n",
      "date_mutation                          2023-01-05         2023-01-03   \n",
      "numero_disposition                              1                  1   \n",
      "nature_mutation                             Vente              Vente   \n",
      "valeur_fonciere                         1070000.0           152200.0   \n",
      "adresse_numero                              159.0             2914.0   \n",
      "adresse_suffixe                               NaN                NaN   \n",
      "adresse_nom_voie                   ALL DES HETRES      RTE DE PONCIN   \n",
      "adresse_code_voie                            0124               0107   \n",
      "code_postal                                1630.0             1450.0   \n",
      "code_commune                                 1354               1404   \n",
      "nom_commune                   Saint-Genis-Pouilly  Serrières-sur-Ain   \n",
      "code_departement                                1                  1   \n",
      "ancien_code_commune                           NaN                NaN   \n",
      "ancien_nom_commune                            NaN                NaN   \n",
      "id_parcelle                        01354000BD0336     014040000D2317   \n",
      "ancien_id_parcelle                            NaN                NaN   \n",
      "numero_volume                                 NaN                NaN   \n",
      "lot1_numero                                     8                NaN   \n",
      "lot1_surface_carrez                           NaN                NaN   \n",
      "lot2_numero                                   NaN                NaN   \n",
      "lot2_surface_carrez                           NaN                NaN   \n",
      "lot3_numero                                   NaN                NaN   \n",
      "lot3_surface_carrez                           NaN                NaN   \n",
      "lot4_numero                                   NaN                NaN   \n",
      "lot4_surface_carrez                           NaN                NaN   \n",
      "lot5_numero                                   NaN                NaN   \n",
      "lot5_surface_carrez                           NaN                NaN   \n",
      "nombre_lots                                     1                  0   \n",
      "code_type_local                               3.0                1.0   \n",
      "type_local                             Dépendance             Maison   \n",
      "surface_reelle_bati                           NaN               64.0   \n",
      "nombre_pieces_principales                     0.0                3.0   \n",
      "code_nature_culture                           NaN                  S   \n",
      "nature_culture                                NaN               sols   \n",
      "code_nature_culture_speciale                  NaN                NaN   \n",
      "nature_culture_speciale                       NaN                NaN   \n",
      "surface_terrain                               NaN              988.0   \n",
      "longitude                                6.020204           5.438273   \n",
      "latitude                                46.247228          46.129859   \n",
      "\n",
      "                                                4                    5  \\\n",
      "id_mutation                                2023-3               2023-3   \n",
      "date_mutation                          2023-01-05           2023-01-05   \n",
      "numero_disposition                              1                    1   \n",
      "nature_mutation                             Vente                Vente   \n",
      "valeur_fonciere                          269000.0             269000.0   \n",
      "adresse_numero                              427.0                427.0   \n",
      "adresse_suffixe                                 T                    T   \n",
      "adresse_nom_voie                 CHE DE L'AUBEPIN     CHE DE L'AUBEPIN   \n",
      "adresse_code_voie                            0040                 0040   \n",
      "code_postal                                1800.0               1800.0   \n",
      "code_commune                                 1361                 1361   \n",
      "nom_commune                   Saint-Jean-de-Niost  Saint-Jean-de-Niost   \n",
      "code_departement                                1                    1   \n",
      "ancien_code_commune                           NaN                  NaN   \n",
      "ancien_nom_commune                            NaN                  NaN   \n",
      "id_parcelle                        013610000B2405       013610000B2405   \n",
      "ancien_id_parcelle                            NaN                  NaN   \n",
      "numero_volume                                 NaN                  NaN   \n",
      "lot1_numero                                   NaN                  NaN   \n",
      "lot1_surface_carrez                           NaN                  NaN   \n",
      "lot2_numero                                   NaN                  NaN   \n",
      "lot2_surface_carrez                           NaN                  NaN   \n",
      "lot3_numero                                   NaN                  NaN   \n",
      "lot3_surface_carrez                           NaN                  NaN   \n",
      "lot4_numero                                   NaN                  NaN   \n",
      "lot4_surface_carrez                           NaN                  NaN   \n",
      "lot5_numero                                   NaN                  NaN   \n",
      "lot5_surface_carrez                           NaN                  NaN   \n",
      "nombre_lots                                     0                    0   \n",
      "code_type_local                               1.0                  3.0   \n",
      "type_local                                 Maison           Dépendance   \n",
      "surface_reelle_bati                          73.0                  NaN   \n",
      "nombre_pieces_principales                     3.0                  0.0   \n",
      "code_nature_culture                             S                    S   \n",
      "nature_culture                               sols                 sols   \n",
      "code_nature_culture_speciale                  NaN                  NaN   \n",
      "nature_culture_speciale                       NaN                  NaN   \n",
      "surface_terrain                             835.0                835.0   \n",
      "longitude                                5.225844             5.225844   \n",
      "latitude                                45.853513            45.853513   \n",
      "\n",
      "                                                6                       7  \\\n",
      "id_mutation                                2023-3                  2023-4   \n",
      "date_mutation                          2023-01-05              2023-01-03   \n",
      "numero_disposition                              1                       1   \n",
      "nature_mutation                             Vente                   Vente   \n",
      "valeur_fonciere                          269000.0                770000.0   \n",
      "adresse_numero                              427.0                   159.0   \n",
      "adresse_suffixe                                 T                       A   \n",
      "adresse_nom_voie                 CHE DE L'AUBEPIN  RUE DU PARC DE VILLARD   \n",
      "adresse_code_voie                            0040                    0151   \n",
      "code_postal                                1800.0                  1210.0   \n",
      "code_commune                                 1361                    1281   \n",
      "nom_commune                   Saint-Jean-de-Niost                   Ornex   \n",
      "code_departement                                1                       1   \n",
      "ancien_code_commune                           NaN                     NaN   \n",
      "ancien_nom_commune                            NaN                     NaN   \n",
      "id_parcelle                        013610000B2405          01281000AD0041   \n",
      "ancien_id_parcelle                            NaN                     NaN   \n",
      "numero_volume                                 NaN                     NaN   \n",
      "lot1_numero                                   NaN                     NaN   \n",
      "lot1_surface_carrez                           NaN                     NaN   \n",
      "lot2_numero                                   NaN                     NaN   \n",
      "lot2_surface_carrez                           NaN                     NaN   \n",
      "lot3_numero                                   NaN                     NaN   \n",
      "lot3_surface_carrez                           NaN                     NaN   \n",
      "lot4_numero                                   NaN                     NaN   \n",
      "lot4_surface_carrez                           NaN                     NaN   \n",
      "lot5_numero                                   NaN                     NaN   \n",
      "lot5_surface_carrez                           NaN                     NaN   \n",
      "nombre_lots                                     0                       0   \n",
      "code_type_local                               3.0                     1.0   \n",
      "type_local                             Dépendance                  Maison   \n",
      "surface_reelle_bati                           NaN                   136.0   \n",
      "nombre_pieces_principales                     0.0                     7.0   \n",
      "code_nature_culture                             S                       S   \n",
      "nature_culture                               sols                    sols   \n",
      "code_nature_culture_speciale                  NaN                     NaN   \n",
      "nature_culture_speciale                       NaN                     NaN   \n",
      "surface_terrain                             835.0                   921.0   \n",
      "longitude                                5.225844                6.083444   \n",
      "latitude                                45.853513               46.279993   \n",
      "\n",
      "                                           8  \n",
      "id_mutation                           2023-5  \n",
      "date_mutation                     2023-01-06  \n",
      "numero_disposition                         1  \n",
      "nature_mutation                        Vente  \n",
      "valeur_fonciere                       6820.0  \n",
      "adresse_numero                           NaN  \n",
      "adresse_suffixe                          NaN  \n",
      "adresse_nom_voie               ETANG DU BOIS  \n",
      "adresse_code_voie                       B062  \n",
      "code_postal                           1480.0  \n",
      "code_commune                            1446  \n",
      "nom_commune                       Villeneuve  \n",
      "code_departement                           1  \n",
      "ancien_code_commune                      NaN  \n",
      "ancien_nom_commune                       NaN  \n",
      "id_parcelle                   01446000ZL0019  \n",
      "ancien_id_parcelle                       NaN  \n",
      "numero_volume                            NaN  \n",
      "lot1_numero                              NaN  \n",
      "lot1_surface_carrez                      NaN  \n",
      "lot2_numero                              NaN  \n",
      "lot2_surface_carrez                      NaN  \n",
      "lot3_numero                              NaN  \n",
      "lot3_surface_carrez                      NaN  \n",
      "lot4_numero                              NaN  \n",
      "lot4_surface_carrez                      NaN  \n",
      "lot5_numero                              NaN  \n",
      "lot5_surface_carrez                      NaN  \n",
      "nombre_lots                                0  \n",
      "code_type_local                          NaN  \n",
      "type_local                               NaN  \n",
      "surface_reelle_bati                      NaN  \n",
      "nombre_pieces_principales                NaN  \n",
      "code_nature_culture                        T  \n",
      "nature_culture                        terres  \n",
      "code_nature_culture_speciale             NaN  \n",
      "nature_culture_speciale                  NaN  \n",
      "surface_terrain                      17050.0  \n",
      "longitude                           4.879012  \n",
      "latitude                           46.021213  \n"
     ]
    }
   ],
   "source": [
    "# url = \"https://static.data.gouv.fr/resources/demandes-de-valeurs-foncieres/20241008-071041/valeursfoncieres-2023.txt.zip\"\n",
    "\n",
    "url = \"https://files.data.gouv.fr/geo-dvf/latest/csv/2023/full.csv.gz\"\n",
    "# Envoyer une requête HTTP pour obtenir le fichier CSV\n",
    "\n",
    "downloaded_file = \"full.csv.gz\"\n",
    "response = rq.get(url)\n",
    "\n",
    "with open(downloaded_file, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Décompresser le fichier\n",
    "with gzip.open(downloaded_file, 'rb') as f_in:\n",
    "    with open(\"full.csv\", 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# Charger le fichier CSV dans un DataFrame\n",
    "df = pd.read_csv(\"full.csv\",encoding=\"utf-8\")\n",
    "\n",
    "## Affiche la première ligne et et toutes les variables\n",
    "premiere_ligne = df.iloc[0:9].T\n",
    "print(premiere_ligne)\n",
    "\n",
    "# Optionnel : supprimer le fichier compressé après décompression\n",
    "os.remove(\"full.csv.gz\")\n",
    "os.remove(\"full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Première analyse : afficher toutes les variables, leurs types et le pourcentage des transactions non renseignées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Nom de la colonne     Type\n",
      "id_mutation                                    id_mutation   object\n",
      "date_mutation                                date_mutation   object\n",
      "numero_disposition                      numero_disposition    int64\n",
      "nature_mutation                            nature_mutation   object\n",
      "valeur_fonciere                            valeur_fonciere  float64\n",
      "adresse_numero                              adresse_numero  float64\n",
      "adresse_suffixe                            adresse_suffixe   object\n",
      "adresse_nom_voie                          adresse_nom_voie   object\n",
      "adresse_code_voie                        adresse_code_voie   object\n",
      "code_postal                                    code_postal  float64\n",
      "code_commune                                  code_commune   object\n",
      "nom_commune                                    nom_commune   object\n",
      "code_departement                          code_departement   object\n",
      "ancien_code_commune                    ancien_code_commune  float64\n",
      "ancien_nom_commune                      ancien_nom_commune   object\n",
      "id_parcelle                                    id_parcelle   object\n",
      "ancien_id_parcelle                      ancien_id_parcelle  float64\n",
      "numero_volume                                numero_volume   object\n",
      "lot1_numero                                    lot1_numero   object\n",
      "lot1_surface_carrez                    lot1_surface_carrez  float64\n",
      "lot2_numero                                    lot2_numero   object\n",
      "lot2_surface_carrez                    lot2_surface_carrez  float64\n",
      "lot3_numero                                    lot3_numero   object\n",
      "lot3_surface_carrez                    lot3_surface_carrez  float64\n",
      "lot4_numero                                    lot4_numero  float64\n",
      "lot4_surface_carrez                    lot4_surface_carrez  float64\n",
      "lot5_numero                                    lot5_numero   object\n",
      "lot5_surface_carrez                    lot5_surface_carrez  float64\n",
      "nombre_lots                                    nombre_lots    int64\n",
      "code_type_local                            code_type_local  float64\n",
      "type_local                                      type_local   object\n",
      "surface_reelle_bati                    surface_reelle_bati  float64\n",
      "nombre_pieces_principales        nombre_pieces_principales  float64\n",
      "code_nature_culture                    code_nature_culture   object\n",
      "nature_culture                              nature_culture   object\n",
      "code_nature_culture_speciale  code_nature_culture_speciale   object\n",
      "nature_culture_speciale            nature_culture_speciale   object\n",
      "surface_terrain                            surface_terrain  float64\n",
      "longitude                                        longitude  float64\n",
      "latitude                                          latitude  float64\n",
      "En 2023, il y a 0.89% des 3799407 transactions réalisées en France qui ne sont pas renseignées dans la base DVF.\n"
     ]
    }
   ],
   "source": [
    "# Création d'un DataFrame avec les noms des colonnes et leurs types\n",
    "column_types = pd.DataFrame({\n",
    "    'Nom de la colonne': df.columns,\n",
    "    'Type': df.dtypes\n",
    "})\n",
    "\n",
    "# Affichage du DataFrame avec les noms de colonnes et leurs types\n",
    "print(column_types)\n",
    "\n",
    "# Nombre total de transactions réalisées en France\n",
    "total_transactions = df.shape[0]\n",
    "\n",
    "# Nombre de transactions manquantes dans la colonne 'valeur_fonciere'\n",
    "nan_transactions = df['valeur_fonciere'].isna().sum()\n",
    "\n",
    "# Calcul du pourcentage de valeurs manquantes\n",
    "pourcentage_nan = (nan_transactions / total_transactions) * 100\n",
    "\n",
    "# Affichage de la phrase\n",
    "print(f\"En 2023, il y a {pourcentage_nan:.2f}% des {total_transactions} transactions réalisées en France qui ne sont pas renseignées dans la base DVF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premiers filtres\n",
    "1) Suppression de toutes les colonnes non utilisées\n",
    "2) Suppression de toutes les transactions non renseignées\n",
    "3) Reconstitution des adresses complètes\n",
    "\n",
    "4) Retenir toutes les transactions qui correspondent à des ventes\n",
    "5) Géolocaliser toutes les transactions qui ne le sont pas dans la base originelle\n",
    "6) Renseigner les départements et régions\n",
    "\n",
    "7) On ne garde que les biens particuliers (appartements et maisons)\n",
    "8) Vérifier que la surface est renseignée\n",
    "9) Filtre sur les seuls appartements\n",
    "10) Exclure les biens dans les DROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Première opération : alléger le dataset\n",
    "\n",
    "colonnes_a_supprimer = ['id_mutation',\n",
    "                        'adresse_suffixe',\n",
    "                        'id_parcelle',\n",
    "                        'numero_disposition',\n",
    "                        'code_nature_culture',\n",
    "                        'ancien_code_commune',\n",
    "                        'ancien_nom_commune',\n",
    "                        'ancien_id_parcelle',\n",
    "                        'numero_volume',\n",
    "                        'code_nature_culture_speciale',\n",
    "                        'nature_culture_speciale',\n",
    "                        'lot1_numero',\n",
    "                        'lot2_numero',\n",
    "                        'lot3_numero',\n",
    "                        'lot4_numero',\n",
    "                        'lot5_numero',\n",
    "                        'lot1_surface_carrez',\n",
    "                        'lot2_surface_carrez',\n",
    "                        'lot3_surface_carrez',\n",
    "                        'lot4_surface_carrez',\n",
    "                        'lot5_surface_carrez'\n",
    "                        ]\n",
    "\n",
    "df.drop(columns=colonnes_a_supprimer, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 78\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Fonction pour télécharger et décompresser un fichier\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# def telecharger_et_decompresser(url, fichier_destination):\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     reponse = rq.get(url)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m#     use_dictionary=True  # Active l'encodage par dictionnaire\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[43mdf_concatene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraitement terminé. Fichier enregistré sous \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvaleursfoncieres_2019_2023.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\formats\\csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[0;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[1;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[0;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:1410\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[1;32m-> 1410\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:466\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_values_for_csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:780\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[1;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    778\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[0;32m    779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:7834\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[1;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[0;32m   7831\u001b[0m mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m   7833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quoting:\n\u001b[1;32m-> 7834\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7835\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7836\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# URL de base pour les fichiers DVF\n",
    "base_url = \"https://files.data.gouv.fr/geo-dvf/latest/csv/{year}/full.csv.gz\"\n",
    "\n",
    "# Liste des années\n",
    "annees = range(2019, 2024)\n",
    "\n",
    "# Colonnes à supprimer\n",
    "colonnes_a_supprimer = [\n",
    "    'id_mutation', 'adresse_suffixe', 'id_parcelle', 'numero_disposition',\n",
    "    'code_nature_culture', 'ancien_code_commune', 'ancien_nom_commune',\n",
    "    'ancien_id_parcelle', 'numero_volume', 'code_nature_culture_speciale',\n",
    "    'nature_culture_speciale', 'lot1_numero', 'lot2_numero', 'lot3_numero',\n",
    "    'lot4_numero', 'lot5_numero', 'lot1_surface_carrez', 'lot2_surface_carrez',\n",
    "    'lot3_surface_carrez', 'lot4_surface_carrez', 'lot5_surface_carrez'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4656\\773889705.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4656\\773889705.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4656\\773889705.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4656\\773889705.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4656\\773889705.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4656\\773889705.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x1a7b7d72840>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "# Boucle pour traiter tous les fichiers\n",
    "for annee in annees:\n",
    "    df = process_data.traiter_fichier(annee, base_url, colonnes_a_supprimer)\n",
    "    dataframes.append(df)\n",
    "\n",
    "df_concatene = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes spécifiques en chaînes de caractères\n",
    "colonnes_a_convertir = ['adresse_code_voie', 'code_commune', 'code_departement']\n",
    "df_concatene = process_data.convertir_en_str(df_concatene, colonnes_a_convertir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatene.to_parquet(\n",
    "    \"data/dvf.parquet\",\n",
    "    index=False,\n",
    "    compression=\"gzip\",\n",
    "    engine=\"pyarrow\",\n",
    "    use_dictionary=True  # Active l'encodage par dictionnaire\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2ème opération (filtre) : Supprimer toutes les transactions NaN\n",
    "df = df.dropna(subset=['valeur_fonciere'])\n",
    "\n",
    "print(df['valeur_fonciere'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "object\n",
      "float64\n",
      "object\n",
      "0    01354\n",
      "1    01354\n",
      "2    01354\n",
      "3    01404\n",
      "4    01361\n",
      "Name: code_commune, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3ème opération : conversion des adresses en string\n",
    "\n",
    "print(df['adresse_numero'].dtype)\n",
    "print(df['adresse_nom_voie'].dtype)\n",
    "print(df['code_postal'].dtype)\n",
    "print(df['nom_commune'].dtype)\n",
    "\n",
    "colonnes_a_nettoyer = ['adresse_numero', 'code_postal']\n",
    "df = process_data.nettoyer_colonnes(df, colonnes_a_nettoyer)\n",
    "# Convertir la colonne 'code_commune' en type string\n",
    "df['code_commune'] = df['code_commune'].astype('string')\n",
    "\n",
    "# Ajouter un '0' au début si la chaîne a 4 caractères\n",
    "df['code_commune'] = [x.zfill(5) if len(x) == 4 else x for x in df['code_commune']]\n",
    "\n",
    "# Vérifier les résultats\n",
    "print(df['code_commune'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  abreviation type_voie_complet\n",
      "0         RUE               Rue\n",
      "1          AV            Avenue\n",
      "2         RTE             Route\n",
      "3         CHE            Chemin\n",
      "4          BD         Boulevard\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "check_abbreviation() missing 1 required positional argument: 'abbreviations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m abbreviations \u001b[38;5;241m=\u001b[39m voie[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabreviation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Appliquer la fonction à la colonne 'adresse_nom_voie'\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[43mprocess_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_abbreviation\u001b[49m\u001b[43m(\u001b[49m\u001b[43madresse\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m adresse \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madresse_nom_voie\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Décomposer les résultats dans les colonnes 'type_voie' et 'nom_voie'\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_voie\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[1;31mTypeError\u001b[0m: check_abbreviation() missing 1 required positional argument: 'abbreviations'"
     ]
    }
   ],
   "source": [
    "# 4ème opération (si besoin de géolocalisation) : Compléter par le type de voie\n",
    "\n",
    "voie = pd.read_csv(\"data/voie.csv\",sep=\";\",encoding=\"utf-8\")\n",
    "print(voie.head())\n",
    "\n",
    "# Liste des abréviations de types de voie\n",
    "abbreviations = voie['abreviation'].tolist()\n",
    "\n",
    "# Appliquer la fonction à la colonne 'adresse_nom_voie'\n",
    "result = [process_data.check_abbreviation(adresse) for adresse in df['adresse_nom_voie']]\n",
    "\n",
    "# Décomposer les résultats dans les colonnes 'type_voie' et 'nom_voie'\n",
    "df['type_voie'] = [x[0] for x in result]\n",
    "df['nom_voie'] = [x[1] for x in result]\n",
    "\n",
    "df = df.merge(voie,left_on=['type_voie'],right_on=['abreviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       184 Allée DES HETRES 1630 Saint-Genis-Pouilly\n",
      "1       159 Allée DES HETRES 1630 Saint-Genis-Pouilly\n",
      "2       159 Allée DES HETRES 1630 Saint-Genis-Pouilly\n",
      "3         2914 Route DE PONCIN 1450 Serrières-sur-Ain\n",
      "4    427 Chemin DE L'AUBEPIN 1800 Saint-Jean-de-Niost\n",
      "Name: Adresse, dtype: string\n"
     ]
    }
   ],
   "source": [
    "## 5ème : Réécriture de l'adresse\n",
    "\n",
    "df['Adresse'] = df['adresse_numero'] + ' ' + df['type_voie_complet'] + ' ' + df['nom_voie'] + ' ' + df['code_postal'] + ' ' + df['nom_commune']\n",
    "\n",
    "print(df['Adresse'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes dans df_geolocalisees2 : 2262335\n",
      "\n",
      "Tableau des modalités de 'nature_mutation' avec pourcentages :\n",
      "                                    Nombre de transactions  Pourcentage (%)\n",
      "nature_mutation                                                            \n",
      "Vente                                              2126208             94.0\n",
      "Vente en l'état futur d'achèvement                  116294              5.1\n",
      "Echange                                               8922              0.4\n",
      "Adjudication                                          6541              0.3\n",
      "Vente terrain à bâtir                                 4200              0.2\n",
      "Expropriation                                          170              0.0\n"
     ]
    }
   ],
   "source": [
    "# Nombre total de lignes dans df_geolocalisees2\n",
    "nb_lignes_total = len(df)\n",
    "print(f\"Nombre total de lignes dans df_geolocalisees2 : {nb_lignes_total}\")\n",
    "\n",
    "# Compter les modalités de 'nature_mutation' et calculer les pourcentages\n",
    "modalites_nature_mutation = df['nature_mutation'].value_counts()\n",
    "modalites_nature_mutation_percent = (modalites_nature_mutation / nb_lignes_total * 100).round(1)\n",
    "\n",
    "# Combiner les valeurs et les pourcentages dans un DataFrame\n",
    "tableau_nature_mutation = pd.DataFrame({\n",
    "    'Nombre de transactions': modalites_nature_mutation,\n",
    "    'Pourcentage (%)': modalites_nature_mutation_percent\n",
    "})\n",
    "\n",
    "# Afficher le tableau\n",
    "print(\"\\nTableau des modalités de 'nature_mutation' avec pourcentages :\")\n",
    "print(tableau_nature_mutation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre : on ne conserve que les ventes\n",
    "df = df[df['nature_mutation']=='Vente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['nature_mutation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_geolocalisees = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "  departmentCode           departmentName  regionCode  \\\n",
      "0              1                      Ain        84.0   \n",
      "1              2                    Aisne        32.0   \n",
      "2              3                   Allier        84.0   \n",
      "3              4  Alpes-de-Haute-Provence        93.0   \n",
      "4              5             Hautes-Alpes        93.0   \n",
      "\n",
      "                   regionName  \n",
      "0        Auvergne-Rhône-Alpes  \n",
      "1             Hauts-de-France  \n",
      "2        Auvergne-Rhône-Alpes  \n",
      "3  Provence-Alpes-Côte d'Azur  \n",
      "4  Provence-Alpes-Côte d'Azur  \n",
      "Type de la colonne 'departmentCode': object\n",
      "Modalités de 'departmentCode':\n",
      "['1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15' '16'\n",
      " '17' '18' '19' '21' '22' '23' '24' '25' '26' '27' '28' '29' '2A' '2B'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '57'\n",
      " '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69' '70' '71'\n",
      " '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83' '84' '85'\n",
      " '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '971' '972' '973' '974'\n",
      " '976' '987' '988']\n",
      "[1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28\n",
      " 29 '29' '2A' '2B' '30' 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46\n",
      " 47 48 49 50 51 52 53 54 55 56 58 59 60 61 62 63 64 65 66 69 70 71 72 73\n",
      " 74 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 971 972\n",
      " 973 974 75]\n"
     ]
    }
   ],
   "source": [
    "# Charger les données des codes de région\n",
    "region = pd.read_csv('data/code_region.csv', sep=';')\n",
    "print(region['departmentCode'].dtype)\n",
    "print(df_geolocalisees['code_departement'].dtype)\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "print(region.head())\n",
    "\n",
    "# Vérifier le type de la colonne 'departmentCode'\n",
    "print(f\"Type de la colonne 'departmentCode': {region['departmentCode'].dtype}\")\n",
    "\n",
    "# Vérifier les modalités (valeurs uniques) de 'departmentCode'\n",
    "print(\"Modalités de 'departmentCode':\")\n",
    "print(region['departmentCode'].unique())\n",
    "print(df_geolocalisees['code_departement'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15' '16'\n",
      " '17' '18' '19' '21' '22' '23' '24' '25' '26' '27' '28' '29' '2A' '2B'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '57'\n",
      " '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69' '70' '71'\n",
      " '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83' '84' '85'\n",
      " '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '971' '972' '973' '974'\n",
      " '976' '987' '988']\n",
      "['1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15' '16'\n",
      " '17' '18' '19' '21' '22' '23' '24' '25' '26' '27' '28' '29' '2A' '2B'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '58'\n",
      " '59' '60' '61' '62' '63' '64' '65' '66' '69' '70' '71' '72' '73' '74'\n",
      " '76' '77' '78' '79' '80' '81' '82' '83' '84' '85' '86' '87' '88' '89'\n",
      " '90' '91' '92' '93' '94' '95' '971' '972' '973' '974' '75']\n"
     ]
    }
   ],
   "source": [
    "region['departmentCode'] = region['departmentCode'].astype(str)\n",
    "df_geolocalisees['code_departement'] = df_geolocalisees['code_departement'].astype(str)\n",
    "\n",
    "print(region['departmentCode'].unique())\n",
    "print(df_geolocalisees['code_departement'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Nombre de transactions  Part du total (%)\n",
      "regionName                                                           \n",
      "Auvergne-Rhône-Alpes                        273064          12.842770\n",
      "Bourgogne-Franche-Comté                     106350           5.001862\n",
      "Bretagne                                    103028           4.845622\n",
      "Centre-Val de Loire                          94763           4.456902\n",
      "Corse                                         5306           0.249552\n",
      "Grand Est                                    88742           4.173721\n",
      "Guadeloupe                                    4029           0.189492\n",
      "Guyane                                        2311           0.108691\n",
      "Hauts-de-France                             173535           8.161713\n",
      "La Réunion                                   16526           0.777252\n",
      "Martinique                                    3833           0.180274\n",
      "Normandie                                   115664           5.439919\n",
      "Nouvelle-Aquitaine                          215207          10.121634\n",
      "Occitanie                                   217800          10.243589\n",
      "Pays de la Loire                            126624           5.955391\n",
      "Provence-Alpes-Côte d'Azur                  219780          10.336712\n",
      "Île-de-France                               359646          16.914902\n"
     ]
    }
   ],
   "source": [
    "#Fusionner df_geolocalisees avec les codes de région\n",
    "df_geolocalisees = df_geolocalisees.merge(region, left_on=[\"code_departement\"], right_on=['departmentCode'], how='left')\n",
    "\n",
    "df_geolocalisees['regionCode'] = df_geolocalisees['regionCode'].astype('Int64')  # Utilise Int64 pour gérer les valeurs manquantes\n",
    "#Compter le nombre de transactions par région\n",
    "\n",
    "transactions_par_region = df_geolocalisees.groupby('regionName').size()\n",
    "\n",
    "# Calculer le total des transactions\n",
    "total_transactions = transactions_par_region.sum()\n",
    "\n",
    "# Calculer la part de chaque région dans le total des transactions\n",
    "part_region = (transactions_par_region / total_transactions) * 100\n",
    "\n",
    "# Créer un DataFrame avec les résultats\n",
    "tableau_regions = pd.DataFrame({\n",
    "    'Nombre de transactions': transactions_par_region,\n",
    "    'Part du total (%)': part_region\n",
    "})\n",
    "\n",
    "# Afficher le tableau des régions\n",
    "print(tableau_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer les Départements et Régions Outre-Mer\n",
    "df_geolocalisees = df_geolocalisees[~df_geolocalisees['regionName'].isin(['Guyane', 'Martinique', 'Guadeloupe', 'La Réunion', 'Mayotte'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Nom de la colonne            Type\n",
      "date_mutation                          date_mutation          object\n",
      "valeur_fonciere                      valeur_fonciere         float64\n",
      "adresse_numero                        adresse_numero  string[python]\n",
      "adresse_nom_voie                    adresse_nom_voie          object\n",
      "adresse_code_voie                  adresse_code_voie          object\n",
      "code_postal                              code_postal  string[python]\n",
      "code_commune                            code_commune          object\n",
      "nom_commune                              nom_commune          object\n",
      "code_departement                    code_departement          object\n",
      "nombre_lots                              nombre_lots           int64\n",
      "code_type_local                      code_type_local         float64\n",
      "type_local                                type_local          object\n",
      "surface_reelle_bati              surface_reelle_bati         float64\n",
      "nombre_pieces_principales  nombre_pieces_principales         float64\n",
      "nature_culture                        nature_culture          object\n",
      "surface_terrain                      surface_terrain         float64\n",
      "longitude                                  longitude         float64\n",
      "latitude                                    latitude         float64\n",
      "type_voie                                  type_voie          object\n",
      "nom_voie                                    nom_voie          object\n",
      "abreviation                              abreviation          object\n",
      "type_voie_complet                  type_voie_complet          object\n",
      "Adresse                                      Adresse  string[python]\n",
      "departmentCode                        departmentCode          object\n",
      "departmentName                        departmentName          object\n",
      "regionCode                                regionCode           Int64\n",
      "regionName                                regionName          object\n",
      "  date_mutation  valeur_fonciere adresse_numero  adresse_nom_voie  \\\n",
      "0    2023-01-05        1070000.0            184    ALL DES HETRES   \n",
      "1    2023-01-05        1070000.0            159    ALL DES HETRES   \n",
      "2    2023-01-05        1070000.0            159    ALL DES HETRES   \n",
      "3    2023-01-03         152200.0           2914     RTE DE PONCIN   \n",
      "4    2023-01-05         269000.0            427  CHE DE L'AUBEPIN   \n",
      "\n",
      "  adresse_code_voie code_postal code_commune          nom_commune  \\\n",
      "0              0124        1630        01354  Saint-Genis-Pouilly   \n",
      "1              0124        1630        01354  Saint-Genis-Pouilly   \n",
      "2              0124        1630        01354  Saint-Genis-Pouilly   \n",
      "3              0107        1450        01404    Serrières-sur-Ain   \n",
      "4              0040        1800        01361  Saint-Jean-de-Niost   \n",
      "\n",
      "  code_departement  nombre_lots  ...   latitude type_voie      nom_voie  \\\n",
      "0                1            1  ...  46.247458       ALL    DES HETRES   \n",
      "1                1            1  ...  46.247228       ALL    DES HETRES   \n",
      "2                1            1  ...  46.247228       ALL    DES HETRES   \n",
      "3                1            0  ...  46.129859       RTE     DE PONCIN   \n",
      "4                1            0  ...  45.853513       CHE  DE L'AUBEPIN   \n",
      "\n",
      "   abreviation type_voie_complet  \\\n",
      "0          ALL             Allée   \n",
      "1          ALL             Allée   \n",
      "2          ALL             Allée   \n",
      "3          RTE             Route   \n",
      "4          CHE            Chemin   \n",
      "\n",
      "                                            Adresse  departmentCode  \\\n",
      "0     184 Allée DES HETRES 1630 Saint-Genis-Pouilly               1   \n",
      "1     159 Allée DES HETRES 1630 Saint-Genis-Pouilly               1   \n",
      "2     159 Allée DES HETRES 1630 Saint-Genis-Pouilly               1   \n",
      "3       2914 Route DE PONCIN 1450 Serrières-sur-Ain               1   \n",
      "4  427 Chemin DE L'AUBEPIN 1800 Saint-Jean-de-Niost               1   \n",
      "\n",
      "   departmentName regionCode            regionName  \n",
      "0             Ain         84  Auvergne-Rhône-Alpes  \n",
      "1             Ain         84  Auvergne-Rhône-Alpes  \n",
      "2             Ain         84  Auvergne-Rhône-Alpes  \n",
      "3             Ain         84  Auvergne-Rhône-Alpes  \n",
      "4             Ain         84  Auvergne-Rhône-Alpes  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Création d'un DataFrame avec les noms des colonnes et leurs types\n",
    "column_types = pd.DataFrame({\n",
    "    'Nom de la colonne': df_geolocalisees.columns,\n",
    "    'Type': df_geolocalisees.dtypes\n",
    "})\n",
    "\n",
    "# Affichage du DataFrame avec les noms de colonnes et leurs types\n",
    "print(column_types)\n",
    "\n",
    "print(df_geolocalisees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Pas de pièces > 0 Pièces > 0  \\\n",
      "type_local                                                              \n",
      "Appartement                                           0.2%      99.8%   \n",
      "Dépendance                                          100.0%       0.0%   \n",
      "Local industriel. commercial ou assimilé            100.0%       0.0%   \n",
      "Maison                                                0.1%      99.9%   \n",
      "\n",
      "                                         Surface manquante Surface renseignée  \n",
      "type_local                                                                     \n",
      "Appartement                                           0.0%             100.0%  \n",
      "Dépendance                                          100.0%               0.0%  \n",
      "Local industriel. commercial ou assimilé              3.8%              96.2%  \n",
      "Maison                                                0.0%             100.0%  \n"
     ]
    }
   ],
   "source": [
    "# Calculer la répartition des pièces > 0 par type de bien\n",
    "repartition_pieces = pd.crosstab(\n",
    "    index=df_geolocalisees['type_local'], \n",
    "    columns=df_geolocalisees['nombre_pieces_principales'] > 0, \n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# Calculer la répartition des surfaces renseignées par type de bien\n",
    "repartition_surface = pd.crosstab(\n",
    "    index=df_geolocalisees['type_local'], \n",
    "    columns=df_geolocalisees['surface_reelle_bati'].notna(), \n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# Renommer les colonnes pour chaque répartition\n",
    "repartition_pieces.columns = ['Pas de pièces > 0', 'Pièces > 0']\n",
    "repartition_surface.columns = ['Surface manquante', 'Surface renseignée']\n",
    "\n",
    "# Fusionner les deux tables en une seule\n",
    "repartition_combined = pd.concat([repartition_pieces, repartition_surface], axis=1)\n",
    "\n",
    "# Arrondir et ajouter le signe %\n",
    "repartition_combined = repartition_combined.round(1).astype(str) + '%'\n",
    "\n",
    "# Afficher le tableau combiné\n",
    "print(repartition_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2367473537.py:9: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2367473537.py:10: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur les 2099509 transactions renseignées et géolocalisées, on ne conserve que 954313 (soit 45.5%)transactions représentant 49.3% d'appartements et 50.7% de maisons.\n"
     ]
    }
   ],
   "source": [
    "# One ne garde donc que les maisons et les appartements\n",
    "\n",
    "df_geolocalisees2 = df_geolocalisees[df_geolocalisees['type_local'].isin(['Maison', 'Appartement'])]\n",
    "\n",
    "total_transactions = df_geolocalisees.shape[0]\n",
    "total_transactions2 = df_geolocalisees2.shape[0]\n",
    "\n",
    "# Calcul du nombre d'appartements et de maisons dans ce sous-ensemble\n",
    "appartements = df_geolocalisees2[df_geolocalisees['type_local'] == 'Appartement'].shape[0]\n",
    "maisons = df_geolocalisees2[df_geolocalisees['type_local'] == 'Maison'].shape[0]\n",
    "\n",
    "# Calcul des pourcentages\n",
    "pourcentage = total_transactions2/total_transactions * 100\n",
    "pourcentage_appartements = (appartements / total_transactions2) * 100\n",
    "pourcentage_maisons = (maisons / total_transactions2) * 100\n",
    "\n",
    "# Générer la phrase\n",
    "phrase = f\"Sur les {total_transactions} transactions renseignées et géolocalisées, on ne conserve que {total_transactions2} (soit {pourcentage:.1f}%)\" \\\n",
    "         f\"transactions représentant {pourcentage_appartements:.1f}% d'appartements et {pourcentage_maisons:.1f}% de maisons.\"\n",
    "\n",
    "# Afficher la phrase\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de lignes avec surface renseignée : 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si la surface est renseignée dans la colonne 'surface_reelle_bati'\n",
    "surface_renseignée = df_geolocalisees2['surface_reelle_bati'].notna().sum()\n",
    "\n",
    "# Calcul du nombre total de lignes dans le DataFrame\n",
    "total_lignes = df_geolocalisees2.shape[0]\n",
    "\n",
    "# Calcul du pourcentage de valeurs renseignées\n",
    "pourcentage_surface_renseignée = (surface_renseignée / total_lignes) * 100\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Pourcentage de lignes avec surface renseignée : {pourcentage_surface_renseignée:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'instant, on ne garde que les appartements\n",
    "df_geolocalisees2 = df_geolocalisees2[df_geolocalisees2['type_local'] == 'Appartement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['code_type_local','type_local','surface_terrain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule le prix moyen par mètre carré\n",
    "df_geolocalisees2['prix_m2'] = df_geolocalisees2['valeur_fonciere']/df_geolocalisees2['surface_reelle_bati']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     type_local  valeur_fonciere nature_culture  surface_reelle_bati  \\\n",
      "16  Appartement         430000.0           sols                 51.0   \n",
      "17  Appartement         430000.0           sols                 51.0   \n",
      "19  Appartement         430000.0           sols                 40.0   \n",
      "24  Appartement         430000.0           sols                 48.0   \n",
      "25  Appartement         430000.0           sols                 40.0   \n",
      "32  Appartement          40000.0           sols                 44.0   \n",
      "33  Appartement          40000.0           sols                 50.0   \n",
      "59  Appartement        1040000.0           sols                108.0   \n",
      "60  Appartement        1040000.0           sols                 54.0   \n",
      "61  Appartement        1040000.0           sols                149.0   \n",
      "\n",
      "    surface_terrain       prix_m2  \n",
      "16             89.0   8431.372549  \n",
      "17             89.0   8431.372549  \n",
      "19             99.0  10750.000000  \n",
      "24             99.0   8958.333333  \n",
      "25             99.0  10750.000000  \n",
      "32            123.0    909.090909  \n",
      "33            123.0    800.000000  \n",
      "59            216.0   9629.629630  \n",
      "60            216.0  19259.259259  \n",
      "61            216.0   6979.865772  \n"
     ]
    }
   ],
   "source": [
    "# Problème : certains terrains sont déclarés en habitation\n",
    "# Filtrer les lignes où 'nature_culture' n'est pas NaN\n",
    "df_filtered = df_geolocalisees2[df_geolocalisees2['nature_culture'].notna()]\n",
    "\n",
    "# Sélectionner uniquement les colonnes désirées\n",
    "df_filtered = df_filtered[['type_local','valeur_fonciere','nature_culture', 'surface_reelle_bati', 'surface_terrain', 'prix_m2']]\n",
    "\n",
    "# Afficher les 10 premières lignes\n",
    "print(df_filtered.head(10))\n",
    "\n",
    "df_geolocalisees2 = df_geolocalisees2[df_geolocalisees2['nature_culture'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons : 10729\n",
      "Nombre de lignes après suppression des doublons : 360087\n"
     ]
    }
   ],
   "source": [
    "# Une partie des transactions sont en doublon\n",
    "\n",
    "# Compter les doublons en fonction des colonnes spécifiées\n",
    "nb_doublons = df_geolocalisees2.duplicated(subset=['adresse_nom_voie', 'code_postal', 'surface_reelle_bati', 'valeur_fonciere']).sum()\n",
    "print(f\"Nombre de doublons : {nb_doublons}\")\n",
    "\n",
    "# Supprimer les doublons en gardant la première occurrence\n",
    "df_geolocalisees2 = df_geolocalisees2.drop_duplicates(subset=['adresse_nom_voie', 'code_postal', 'surface_reelle_bati', 'valeur_fonciere'], keep='first')\n",
    "\n",
    "# Vérifier le nouveau nombre de lignes\n",
    "print(f\"Nombre de lignes après suppression des doublons : {len(df_geolocalisees2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne totale des prix en fonction de la surface : 4645.11 €\n",
      "                    regionName  prix_moyen_region  nb_transactions  \\\n",
      "0         Auvergne-Rhône-Alpes        3604.943521            55328   \n",
      "1      Bourgogne-Franche-Comté        2208.715567            13281   \n",
      "2                     Bretagne        3217.213380            14376   \n",
      "3          Centre-Val de Loire        2407.473468             8005   \n",
      "4                        Corse        3762.884222             1965   \n",
      "5                    Grand Est        2088.459393            10425   \n",
      "6              Hauts-de-France        3110.236742            14088   \n",
      "7                    Normandie        2953.461407            13598   \n",
      "8           Nouvelle-Aquitaine        3623.930447            24710   \n",
      "9                    Occitanie        3264.438937            38818   \n",
      "10            Pays de la Loire        3538.854014            14414   \n",
      "11  Provence-Alpes-Côte d'Azur        4778.416606            58154   \n",
      "12               Île-de-France        7880.657027            92925   \n",
      "\n",
      "    pourcentage_appart  pourcentage_maison  \n",
      "0                100.0                 0.0  \n",
      "1                100.0                 0.0  \n",
      "2                100.0                 0.0  \n",
      "3                100.0                 0.0  \n",
      "4                100.0                 0.0  \n",
      "5                100.0                 0.0  \n",
      "6                100.0                 0.0  \n",
      "7                100.0                 0.0  \n",
      "8                100.0                 0.0  \n",
      "9                100.0                 0.0  \n",
      "10               100.0                 0.0  \n",
      "11               100.0                 0.0  \n",
      "12               100.0                 0.0  \n",
      "\n",
      "Moyenne des prix par région en fonction de la surface :\n",
      "regionName\n",
      "Auvergne-Rhône-Alpes          3604.943521\n",
      "Bourgogne-Franche-Comté       2208.715567\n",
      "Bretagne                      3217.213380\n",
      "Centre-Val de Loire           2407.473468\n",
      "Corse                         3762.884222\n",
      "Grand Est                     2088.459393\n",
      "Hauts-de-France               3110.236742\n",
      "Normandie                     2953.461407\n",
      "Nouvelle-Aquitaine            3623.930447\n",
      "Occitanie                     3264.438937\n",
      "Pays de la Loire              3538.854014\n",
      "Provence-Alpes-Côte d'Azur    4778.416606\n",
      "Île-de-France                 7880.657027\n",
      "dtype: float64\n",
      "\n",
      "Moyenne des prix par type d'appartement en fonction de la surface :\n",
      "type_local\n",
      "Appartement    4645.107041\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcul de la moyenne des prix totale en fonction de la surface\n",
    "prix_moyen_m2 = df_geolocalisees2['valeur_fonciere'].sum() / df_geolocalisees2['surface_reelle_bati'].sum()\n",
    "print(f\"Moyenne totale des prix en fonction de la surface : {prix_moyen_m2:.2f} €\")\n",
    "\n",
    "# Calcul de la moyenne des prix par région\n",
    "prix_moyen_region = df_geolocalisees2.groupby('regionName')['valeur_fonciere'].sum() / df_geolocalisees2.groupby('regionName')['surface_reelle_bati'].sum()\n",
    "\n",
    "# Calcul de la moyenne des prix par type d'appartement en fonction de la surface\n",
    "prix_moyen_type = df_geolocalisees2.groupby('type_local')['valeur_fonciere'].sum() / df_geolocalisees2.groupby('type_local')['surface_reelle_bati'].sum()\n",
    "\n",
    "# Calcul du nombre de transactions par région\n",
    "nb_transactions_region = df_geolocalisees2.groupby('regionName').size()\n",
    "\n",
    "# Calcul du pourcentage d'appartements et de maisons par région\n",
    "nb_transactions_appart = df_geolocalisees2[df_geolocalisees2['type_local'] == \"Appartement\"].groupby('regionName').size()\n",
    "nb_transactions_maison = df_geolocalisees2[df_geolocalisees2['type_local'] == \"Maison\"].groupby('regionName').size()\n",
    "\n",
    "# Calculer le pourcentage pour chaque type par région\n",
    "pourcentage_appart = (nb_transactions_appart / nb_transactions_region * 100).fillna(0)\n",
    "pourcentage_maison = (nb_transactions_maison / nb_transactions_region * 100).fillna(0)\n",
    "\n",
    "# Combiner toutes les informations dans un DataFrame final\n",
    "stats_region = pd.DataFrame({\n",
    "    'prix_moyen_region': prix_moyen_region,\n",
    "    'nb_transactions': nb_transactions_region,\n",
    "    'pourcentage_appart': pourcentage_appart,\n",
    "    'pourcentage_maison': pourcentage_maison\n",
    "}).reset_index()\n",
    "\n",
    "# Afficher le tableau final\n",
    "print(stats_region)\n",
    "# Afficher les tableaux de moyennes\n",
    "print(\"\\nMoyenne des prix par région en fonction de la surface :\")\n",
    "print(prix_moyen_region)\n",
    "\n",
    "print(\"\\nMoyenne des prix par type d'appartement en fonction de la surface :\")\n",
    "print(prix_moyen_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    regionName\n",
      "0                Île-de-France\n",
      "1          Centre-Val de Loire\n",
      "2      Bourgogne-Franche-Comté\n",
      "3                    Normandie\n",
      "4              Hauts-de-France\n",
      "5                    Grand Est\n",
      "6             Pays de la Loire\n",
      "7                     Bretagne\n",
      "8           Nouvelle-Aquitaine\n",
      "9                   Guadeloupe\n",
      "10                  Martinique\n",
      "11                      Guyane\n",
      "12                  La Réunion\n",
      "13                     Mayotte\n",
      "14                   Occitanie\n",
      "15        Auvergne-Rhône-Alpes\n",
      "16  Provence-Alpes-Côte d'Azur\n",
      "17                       Corse\n",
      "                    regionName\n",
      "0                Île-de-France\n",
      "1   Provence-Alpes-Côte d'Azur\n",
      "2         Auvergne-Rhône-Alpes\n",
      "3                    Occitanie\n",
      "4           Nouvelle-Aquitaine\n",
      "5             Pays de la Loire\n",
      "6                     Bretagne\n",
      "7              Hauts-de-France\n",
      "8                    Normandie\n",
      "9      Bourgogne-Franche-Comté\n",
      "10                   Grand Est\n",
      "11         Centre-Val de Loire\n",
      "12                       Corse\n"
     ]
    }
   ],
   "source": [
    "# URL du fichier GeoJSON des régions de France\n",
    "url_region = \"https://france-geojson.gregoiredavid.fr/repo/regions.geojson\"\n",
    "\n",
    "# Récupérer le fichier GeoJSON des régions de France\n",
    "response = rq.get(url_region)\n",
    "regions_geojson = response.json()\n",
    "\n",
    "# Créer une liste pour stocker les noms des régions\n",
    "region_names = []\n",
    "\n",
    "# Extraire les noms des régions depuis les propriétés de chaque feature\n",
    "for feature in regions_geojson['features']:\n",
    "    region_name = feature['properties']['nom']\n",
    "    region_names.append(region_name)\n",
    "\n",
    "# Créer un DataFrame avec les noms des régions\n",
    "df_regions = pd.DataFrame(region_names, columns=['regionName'])\n",
    "    \n",
    "# Afficher le DataFrame\n",
    "print(df_regions)\n",
    "\n",
    " # Afficher les modalités de la colonne 'regionName'\n",
    "modalites_region = df_geolocalisees2['regionName'].value_counts().reset_index()\n",
    "\n",
    "modalites_region = pd.DataFrame(modalites_region[['regionName']])\n",
    "# Affichage\n",
    "print(modalites_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail sur les zones cotières\n",
    "1) Import des listes des communes littorales\n",
    "2) Calcul des centroïdes des communes (afin d'orienter la visualisation sur la commune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "Type de la colonne 'departmentCode': object\n",
      "Modalités de 'departmentCode':\n",
      "['Ain' 'Aisne' 'Allier' 'Alpes-de-Haute-Provence' 'Hautes-Alpes'\n",
      " 'Alpes-Maritimes' 'Ardèche' 'Ardennes' 'Ariège' 'Aube' 'Aude' 'Aveyron'\n",
      " 'Bouches-du-Rhône' 'Calvados' 'Cantal' 'Charente' 'Charente-Maritime'\n",
      " 'Cher' 'Corrèze' \"Côte-d'Or\" \"Côtes-d'Armor\" 'Creuse' 'Dordogne' 'Doubs'\n",
      " 'Drôme' 'Eure' 'Eure-et-Loir' 'Finistère' 'Corse-du-Sud' 'Haute-Corse'\n",
      " 'Gard' 'Haute-Garonne' 'Gers' 'Gironde' 'Hérault' 'Ille-et-Vilaine'\n",
      " 'Indre' 'Indre-et-Loire' 'Isère' 'Jura' 'Landes' 'Loir-et-Cher' 'Loire'\n",
      " 'Haute-Loire' 'Loire-Atlantique' 'Loiret' 'Lot' 'Lot-et-Garonne' 'Lozère'\n",
      " 'Maine-et-Loire' 'Manche' 'Marne' 'Haute-Marne' 'Mayenne'\n",
      " 'Meurthe-et-Moselle' 'Meuse' 'Morbihan' 'Moselle' 'Nièvre' 'Nord' 'Oise'\n",
      " 'Orne' 'Pas-de-Calais' 'Puy-de-Dôme' 'Pyrénées-Atlantiques'\n",
      " 'Hautes-Pyrénées' 'Pyrénées-Orientales' 'Bas-Rhin' 'Haut-Rhin' 'Rhône'\n",
      " 'Haute-Saône' 'Saône-et-Loire' 'Sarthe' 'Savoie' 'Haute-Savoie' 'Paris'\n",
      " 'Seine-Maritime' 'Seine-et-Marne' 'Yvelines' 'Deux-Sèvres' 'Somme' 'Tarn'\n",
      " 'Tarn-et-Garonne' 'Var' 'Vaucluse' 'Vendée' 'Vienne' 'Haute-Vienne'\n",
      " 'Vosges' 'Yonne' 'Territoire de Belfort' 'Essonne' 'Hauts-de-Seine'\n",
      " 'Seine-Saint-Denis' 'Val-de-Marne' \"Val-d'Oise\" 'Guadeloupe' 'Martinique'\n",
      " 'Guyane' 'La Réunion' 'Mayotte' 'Polynésie Française'\n",
      " 'Nouvelle Calédonie']\n",
      "['Ain' 'Aisne' 'Allier' 'Alpes-de-Haute-Provence' 'Hautes-Alpes'\n",
      " 'Alpes-Maritimes' 'Ardèche' 'Ardennes' 'Ariège' 'Aube' 'Aude' 'Aveyron'\n",
      " 'Bouches-du-Rhône' 'Calvados' 'Cantal' 'Charente' 'Charente-Maritime'\n",
      " 'Cher' 'Corrèze' \"Côte-d'Or\" \"Côtes-d'Armor\" 'Creuse' 'Dordogne' 'Doubs'\n",
      " 'Drôme' 'Eure' 'Eure-et-Loir' 'Finistère' 'Corse-du-Sud' 'Haute-Corse'\n",
      " 'Gard' 'Haute-Garonne' 'Gers' 'Gironde' 'Hérault' 'Ille-et-Vilaine'\n",
      " 'Indre' 'Indre-et-Loire' 'Isère' 'Jura' 'Landes' 'Loir-et-Cher' 'Loire'\n",
      " 'Haute-Loire' 'Loire-Atlantique' 'Loiret' 'Lot' 'Lot-et-Garonne' 'Lozère'\n",
      " 'Maine-et-Loire' 'Manche' 'Marne' 'Haute-Marne' 'Mayenne'\n",
      " 'Meurthe-et-Moselle' 'Meuse' 'Morbihan' 'Nièvre' 'Nord' 'Oise' 'Orne'\n",
      " 'Pas-de-Calais' 'Puy-de-Dôme' 'Pyrénées-Atlantiques' 'Hautes-Pyrénées'\n",
      " 'Pyrénées-Orientales' 'Rhône' 'Haute-Saône' 'Saône-et-Loire' 'Sarthe'\n",
      " 'Savoie' 'Haute-Savoie' 'Seine-Maritime' 'Seine-et-Marne' 'Yvelines'\n",
      " 'Deux-Sèvres' 'Somme' 'Tarn' 'Tarn-et-Garonne' 'Var' 'Vaucluse' 'Vendée'\n",
      " 'Vienne' 'Haute-Vienne' 'Vosges' 'Yonne' 'Territoire de Belfort'\n",
      " 'Essonne' 'Hauts-de-Seine' 'Seine-Saint-Denis' 'Val-de-Marne'\n",
      " \"Val-d'Oise\" 'Paris']\n"
     ]
    }
   ],
   "source": [
    "# Charger les données des codes de région\n",
    "dep = pd.read_csv('data/code_region.csv', sep=';')\n",
    "print(region['departmentName'].dtype)\n",
    "print(df_geolocalisees2['departmentName'].dtype)\n",
    "\n",
    "\n",
    "# Vérifier le type de la colonne 'departmentCode'\n",
    "print(f\"Type de la colonne 'departmentCode': {dep['departmentName'].dtype}\")\n",
    "\n",
    "# Vérifier les modalités (valeurs uniques) de 'departmentCode'\n",
    "print(\"Modalités de 'departmentCode':\")\n",
    "print(dep['departmentName'].unique())\n",
    "print(df_geolocalisees2['departmentName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la variable adresse_py en remplaçant les espaces par des \"+\"\n",
    "df_geolocalisees2['adresse_py'] = df_geolocalisees2['Adresse'].str.replace(' ', '+', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2638450821.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2638450821.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2638450821.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2638450821.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2638450821.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\2638450821.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commune = pd.read_csv('data/communes_code.csv', sep=';',encoding=\"utf-8\")\n",
    "show(commune)\n",
    "# Left_join des codes_communes avec les noms des communes geoJson\n",
    "df_geolocalisees2 = df_geolocalisees2.merge(commune, left_on=[\"code_commune\"], right_on=['code'], how='left')\n",
    "df_geolocalisees2 = df_geolocalisees2.sort_values(by='code_commune', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1427992124.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1427992124.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1427992124.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1427992124.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1427992124.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1427992124.py:2: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x2ad957411c0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cotieres = pd.read_csv(\"data/communes_cotieres.csv\",sep=\";\")\n",
    "show(df_cotieres.head())\n",
    "\n",
    "# # Statistiques par \"Motif du classement\"\n",
    "# stats_motif = df_cotieres.groupby('Motif du classement').agg(\n",
    "#     nombre_communes=('Nom commune', 'nunique'),\n",
    "#     population_totale=('Population', 'sum')\n",
    "# ).reset_index()\n",
    "\n",
    "# # Statistiques par \"Région\"\n",
    "# stats_region = df_cotieres.groupby('Région').agg(\n",
    "#     nombre_communes=('Nom commune', 'nunique'),\n",
    "#     population_totale=('Population', 'sum')\n",
    "# ).reset_index()\n",
    "\n",
    "# # Afficher les résultats\n",
    "# print(stats_motif)\n",
    "# print(stats_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619\n"
     ]
    }
   ],
   "source": [
    "liste_cotieres = df_cotieres['nom'].unique().tolist()\n",
    "\n",
    "print(len(liste_cotieres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geolocalisees3 = df_geolocalisees2[df_geolocalisees2['communeName'].isin(liste_cotieres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur les 51115 transactions renseignées, 0.28% ne sont pas géolocalisées.\n"
     ]
    }
   ],
   "source": [
    "# Combien de transactions ne sont pas géolocalisées ?\n",
    "\n",
    "# Nombre total de transactions renseignées (celles qui ont des valeurs dans 'latitude' et 'longitude')\n",
    "total_transactions_renseignees = df_geolocalisees3.shape[0]\n",
    "\n",
    "# Nombre de lignes où 'latitude' ou 'longitude' est manquant (sans double compte)\n",
    "non_geolocalisees = df_geolocalisees3[df_geolocalisees3['latitude'].isna() | df_geolocalisees3['longitude'].isna()].shape[0]\n",
    "\n",
    "# Calcul du pourcentage de transactions non géolocalisées\n",
    "pourcentage_non_geolocalisees = (non_geolocalisees / total_transactions_renseignees) * 100\n",
    "\n",
    "# Affichage de la phrase\n",
    "print(f\"Sur les {total_transactions_renseignees} transactions renseignées, {pourcentage_non_geolocalisees:.2f}% ne sont pas géolocalisées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1770471222.py:4: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1770471222.py:4: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1770471222.py:4: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1770471222.py:4: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1770471222.py:4: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1770471222.py:4: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x2aeba3c0680>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculer le nombre de transactions par commune\n",
    "nombre_transactions_cotieres = df_geolocalisees3.groupby('communeName').size().reset_index(name='Nombre de transactions')\n",
    "\n",
    "show(nombre_transactions_cotieres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_geolocalisees2[df_geolocalisees2['latitude'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_missing.drop(columns=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = geolocaliser.geolocaliser_actifs(df_missing, 'adresse_py', 'latitude', 'longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatène les DataFrames en réinitialisant l'index\n",
    "df_final = pd.concat([df_geolocalisees3, df_missing], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51115, 31)\n",
      "(1195, 31)\n",
      "(52310, 31)\n"
     ]
    }
   ],
   "source": [
    "# Affiche le DataFrame final pour vérifier la concaténation\n",
    "\n",
    "print(df_geolocalisees3.shape)\n",
    "print(df_missing.shape)\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1743043137.py:9: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1743043137.py:9: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1743043137.py:9: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1743043137.py:9: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1743043137.py:9: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_11792\\1743043137.py:9: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x2ae13697260>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Extraire la liste des communes uniques\n",
    "# df_communes = df_final['communeName'].drop_duplicates().dropna().reset_index(drop=True).to_frame()\n",
    "\n",
    "# # Remplir les coordonnées des mairies\n",
    "# df_communes = geolocaliser.geolocaliser_mairies(df_communes, 'communeName')\n",
    "\n",
    "# show(df_communes)\n",
    "\n",
    "show(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52310\n",
      "33\n",
      "  date_mutation  valeur_fonciere adresse_numero        adresse_nom_voie  \\\n",
      "0    2023-10-05         147886.0             34           BD ALBERT 1ER   \n",
      "1    2023-06-02         219000.0            142  CHE AMES DU PURGATOIRE   \n",
      "2    2023-05-25         480000.0            978       RTE DE SAINT JEAN   \n",
      "3    2023-05-17         169000.0             15               CHE TANIT   \n",
      "4    2023-10-06         360000.0              4     AV COMMANDANT GARBE   \n",
      "\n",
      "  adresse_code_voie code_postal code_commune nom_commune code_departement  \\\n",
      "0              0060        6600        06004     Antibes                6   \n",
      "1              0110        6600        06004     Antibes                6   \n",
      "2              3200        6600        06004     Antibes                6   \n",
      "3              3370        6160        06004     Antibes                6   \n",
      "4              0770        6160        06004     Antibes                6   \n",
      "\n",
      "   nombre_lots  ...  departmentCode   departmentName  regionCode  \\\n",
      "0            2  ...               6  Alpes-Maritimes          93   \n",
      "1            1  ...               6  Alpes-Maritimes          93   \n",
      "2            1  ...               6  Alpes-Maritimes          93   \n",
      "3            1  ...               6  Alpes-Maritimes          93   \n",
      "4            2  ...               6  Alpes-Maritimes          93   \n",
      "\n",
      "                   regionName      prix_m2  \\\n",
      "0  Provence-Alpes-Côte d'Azur  5915.440000   \n",
      "1  Provence-Alpes-Côte d'Azur  4211.538462   \n",
      "2  Provence-Alpes-Côte d'Azur  7272.727273   \n",
      "3  Provence-Alpes-Côte d'Azur  3595.744681   \n",
      "4  Provence-Alpes-Côte d'Azur  6792.452830   \n",
      "\n",
      "                                   adresse_py   code  communeName  \\\n",
      "0        34+Boulevard+ALBERT+1ER+6600+Antibes  06004      Antibes   \n",
      "1  142+Chemin+AMES+DU+PURGATOIRE+6600+Antibes  06004      Antibes   \n",
      "2        978+Route+DE+SAINT+JEAN+6600+Antibes  06004      Antibes   \n",
      "3                15+Chemin+TANIT+6160+Antibes  06004      Antibes   \n",
      "4      4+Avenue+COMMANDANT+GARBE+6160+Antibes  06004      Antibes   \n",
      "\n",
      "  latitude_mairie longitude_mairie  \n",
      "0       43.599404         7.084642  \n",
      "1       43.599404         7.084642  \n",
      "2       43.599404         7.084642  \n",
      "3       43.599404         7.084642  \n",
      "4       43.599404         7.084642  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Effectuer un left join entre df_final et df_communes\n",
    "base_transactions = pd.merge(df_final, df_communes, how='left', left_on='communeName', right_on='communeName')\n",
    "print(base_transactions.shape[0])\n",
    "print(base_transactions.shape[1])\n",
    "\n",
    "# Vérification du résultat\n",
    "print(base_transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transactions = base_transactions.drop(columns=['departmentCode','communeName','code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transactions.to_csv(\"data/base.csv\",sep=\";\",index=False,encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
